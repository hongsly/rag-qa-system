# Generated by Claude Code
"""
Evaluate different retrievers for general NLP queries (not RAG-focused) with manually curated ground truth
"""

evaluation_results = {
    "query_1": {
        "query": "What is attention mechanism in transformers?",
        "dense": {
            "retrieved_ids": [
                "2312.00752_rag_roadmap_asaichunk_450",
                "2312.00752_rag_roadmap_asaichunk_29250",
                "2312.00752_rag_roadmap_asaichunk_32850",
                "2312.00752_rag_roadmap_asaichunk_28800",
                "2307.03172_lost_in_middle_liuchunk_9450"
            ],
            "relevant_ids": [
                "2312.00752_rag_roadmap_asaichunk_450",   # Mentions transformers in various domains
                "2312.00752_rag_roadmap_asaichunk_29250",  # Explicitly mentions "multi-head attention"
                "2312.00752_rag_roadmap_asaichunk_32850",  # Mentions FlashAttention
                "2312.00752_rag_roadmap_asaichunk_28800"   # Mentions "gated attention unit"
            ]
        },
        "sparse": {
            "retrieved_ids": [
                "2312.00752_rag_roadmap_asaichunk_26550",
                "2312.00752_rag_roadmap_asaichunk_4500",
                "2202.01110_rag_survey_lichunk_6750",
                "2312.00752_rag_roadmap_asaichunk_0",
                "2312.00752_rag_roadmap_asaichunk_22500"
            ],
            "relevant_ids": [
                "2202.01110_rag_survey_lichunk_6750"  # Mentions "gating and attention"
            ]
        },
        "hybrid": {
            "retrieved_ids": [
                "2312.00752_rag_roadmap_asaichunk_26550",
                "2312.00752_rag_roadmap_asaichunk_28800",
                "2312.00752_rag_roadmap_asaichunk_0",
                "2312.00752_rag_roadmap_asaichunk_29250",
                "2312.00752_rag_roadmap_asaichunk_4500"
            ],
            "relevant_ids": [
                "2312.00752_rag_roadmap_asaichunk_28800",  # Gated attention unit
                "2312.00752_rag_roadmap_asaichunk_29250"   # Multi-head attention
            ]
        }
    },
    "query_2": {
        "query": "How does BERT pretraining work?",
        "dense": {
            "retrieved_ids": [
                "2107.05720_splade_formalchunk_2250",
                "2004.12832_colbert_khattabchunk_6300",
                "2402.13116_long_context_rag_xuchunk_49500",
                "2004.12832_colbert_khattabchunk_10350",
                "2402.13116_long_context_rag_xuchunk_59400"
            ],
            "relevant_ids": [
                "2107.05720_splade_formalchunk_2250",      # MLM prediction, BERT embeddings
                "2004.12832_colbert_khattabchunk_6300",    # Mentions BERT-based models
                "2004.12832_colbert_khattabchunk_10350"    # Discusses BERT-based models
            ]
        },
        "sparse": {
            "retrieved_ids": [
                "2004.04906_dpr_karpukhinchunk_9900",
                "2004.12832_colbert_khattabchunk_3150",
                "2410.02525_contextual_embeddings_nussbaumchunk_15750",
                "2005.11401_rag_lewischunk_9000",
                "2004.12832_colbert_khattabchunk_4050"
            ],
            "relevant_ids": []  # None really explain BERT pretraining
        },
        "hybrid": {
            "retrieved_ids": [
                "2410.02525_contextual_embeddings_nussbaumchunk_15750",
                "2004.12832_colbert_khattabchunk_3600",
                "2004.04906_dpr_karpukhinchunk_9900",
                "2107.05720_splade_formalchunk_2250",
                "2004.12832_colbert_khattabchunk_3150"
            ],
            "relevant_ids": [
                "2004.12832_colbert_khattabchunk_3600",  # Mentions BERT and ranking
                "2107.05720_splade_formalchunk_2250"     # MLM prediction
            ]
        }
    },
    "query_3": {
        "query": "What is the difference between GPT and BERT?",
        "dense": {
            "retrieved_ids": [
                "2305.14283_query_rewriting_machunk_10800",
                "2305.14552_hallucination_manakulchunk_18000",
                "2004.12832_colbert_khattabchunk_1350",
                "2004.12832_colbert_khattabchunk_3600",
                "2307.03172_lost_in_middle_liuchunk_15300"
            ],
            "relevant_ids": [
                "2305.14552_hallucination_manakulchunk_18000",  # Compares GPT-3.5 with others
                "2004.12832_colbert_khattabchunk_3600"          # Mentions BERT and ELMo
            ]
        },
        "sparse": {
            "retrieved_ids": [
                "2212.10509_cot_retrieval_trivedichunk_22050",
                "2310.06117_step_back_zhengchunk_21600",
                "2212.10496_hyde_gaochunk_6300",
                "2310.06117_step_back_zhengchunk_21150",
                "2210.03629_react_yaochunk_5850"
            ],
            "relevant_ids": [
                "2212.10496_hyde_gaochunk_6300"  # Mentions GPT in comparison table
            ]
        },
        "hybrid": {
            "retrieved_ids": [
                "2004.12832_colbert_khattabchunk_6300",
                "2004.12832_colbert_khattabchunk_10350",
                "2212.10509_cot_retrieval_trivedichunk_22050",
                "2305.14283_query_rewriting_machunk_10800",
                "2310.06117_step_back_zhengchunk_21600"
            ],
            "relevant_ids": [
                "2004.12832_colbert_khattabchunk_6300",   # Discusses BERT-based models
                "2004.12832_colbert_khattabchunk_10350"   # Mentions BERT-based progress
            ]
        }
    }
}


def calculate_precision_at_k(retrieved_ids, relevant_ids, k=5):
    """Calculate precision at k."""
    retrieved_top_k = retrieved_ids[:k]
    true_positives = set(relevant_ids).intersection(retrieved_top_k)
    return len(true_positives) / k


def calculate_mrr(retrieved_ids, relevant_ids):
    """Calculate mean reciprocal rank."""
    relevant_set = set(relevant_ids)
    for rank, doc_id in enumerate(retrieved_ids, start=1):
        if doc_id in relevant_set:
            return 1.0 / rank
    return 0.0


def print_results():
    print("=" * 120)
    print("EVALUATION RESULTS: Dense vs Sparse vs Hybrid Retrieval")
    print("=" * 120)

    all_results = []

    for query_key in ["query_1", "query_2", "query_3"]:
        query_data = evaluation_results[query_key]
        query = query_data["query"]

        print(f"\n{query}")
        print("-" * 120)

        result = {"query": query}

        for method in ["dense", "sparse", "hybrid"]:
            retrieved = query_data[method]["retrieved_ids"]
            relevant = query_data[method]["relevant_ids"]

            precision = calculate_precision_at_k(retrieved, relevant, k=5)
            mrr = calculate_mrr(retrieved, relevant)

            result[f"{method}_precision"] = precision
            result[f"{method}_mrr"] = mrr

            print(f"  {method.upper():8s}: Precision@5 = {precision:.1%} ({len(relevant)}/5 relevant) | MRR = {mrr:.3f}")

        all_results.append(result)

    # Calculate averages
    print("\n" + "=" * 120)
    print("SUMMARY")
    print("=" * 120)

    avg_dense_p = sum(r["dense_precision"] for r in all_results) / len(all_results)
    avg_dense_mrr = sum(r["dense_mrr"] for r in all_results) / len(all_results)

    avg_sparse_p = sum(r["sparse_precision"] for r in all_results) / len(all_results)
    avg_sparse_mrr = sum(r["sparse_mrr"] for r in all_results) / len(all_results)

    avg_hybrid_p = sum(r["hybrid_precision"] for r in all_results) / len(all_results)
    avg_hybrid_mrr = sum(r["hybrid_mrr"] for r in all_results) / len(all_results)

    print(f"\n{'Method':<10s} | {'Avg Precision@5':<20s} | {'Avg MRR':<10s}")
    print("-" * 120)
    print(f"{'Dense':<10s} | {avg_dense_p:>18.1%} | {avg_dense_mrr:>10.3f}")
    print(f"{'Sparse':<10s} | {avg_sparse_p:>18.1%} | {avg_sparse_mrr:>10.3f}")
    print(f"{'Hybrid':<10s} | {avg_hybrid_p:>18.1%} | {avg_hybrid_mrr:>10.3f}")

    print("\n" + "=" * 120)
    if avg_hybrid_p >= 0.85:
        print(f"✅ TARGET MET: Hybrid Precision@5 = {avg_hybrid_p:.1%} (≥ 85%)")
    else:
        print(f"⚠️  TARGET MISSED: Hybrid Precision@5 = {avg_hybrid_p:.1%} (target: ≥ 85%)")
    print("=" * 120)

    return all_results


if __name__ == "__main__":
    print_results()
